amends "package://schema.kdeps.com/core@0.2.2#/Resource.pkl"

actionID = "llmResource"
name = "LLM Chat Resource"
description = "This resource creates a LLM chat session."
category = ""
requires {
        "execResource"
}

local output_file_content = """
@(read?("file:/tmp/output.txt")?.text)
"""

run {
        skipCondition {
                // Conditions under which the execution of this resource should be skipped.
                // If any evaluated condition returns true, the resource execution will be bypassed.
        }
        preflightCheck {
                validations {
                        output_file_content.length != 0
                        // This section expects boolean validations.
                        // If any validation returns false, an exception will be thrown before proceeding to the next step.
                }
                // Custom error message and code to be used if the preflight check fails.
                error {
                        code = 0
                        message = "Empty document received!"
                }
        }

        // Initializes a chat session with the LLM for this resource.
        //
        // This resource offers the following helper functions:
        //
        // - "@(llm.response("ResourceID"))"
        // - "@(llm.prompt("ResourceID"))"
        //
        // To use these in your resource, you can define a local variable as follows:
        //
        // local llmResponse = "@(llm.response("ResourceID"))"
        // You can then access the value with "@(llmResponse)".
        //
        // The "@(...)" syntax enables lazy evaluation, ensuring that values are
        // retrieved only after the result is ready.
        //
        // Note: Each resource is restricted to a single dedicated action. Combining multiple
        // actions within the same resource is not allowed.
        chat {
                model = "llama3.1" // This LLM model needs to be defined in the workflow
                prompt = "\(output_file_content)"

                // Specify if the LLM response should be a structured JSON
                JSONResponse = true

                // If JSONResponse is true, then the structured JSON data will need to have the
                // following keys.
                JSONResponseKeys {
                        "document_type"
                        "document_category"
                        "document_markdown"
                }

                // Specify the files that this LLM will process.
                files {
                        // "@(request.files()[0])"
                }

                // Timeout duration in seconds. This specifies when to terminate the llm session.
                timeoutDuration = 60
        }
}
