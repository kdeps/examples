amends "package://schema.kdeps.com/core@0.2.43#/Workflow.pkl"

AgentID = "huggingface_imagegen_api"
Description = "AI Image Generation API"
Website = ""
Authors {}
Documentation = ""
Repository = ""
HeroImage = ""
AgentIcon = ""

// Version is Required
Version = "1.0.0"

// This section defines the default resource targetActionID that will be executed
// when this API resource is called.
TargetActionID = "responseResource"

// Specify any external resources to use in this AI Agent.
// For example, you can refer to another agent with "@agentName".
Workflows {}

Settings {
        // When set to false, the agent runs in standalone mode, executing once
        // when the Docker container starts and then stops after all resources
        // have been processed.
        APIServerMode = true

        // The API server block contains settings related to the API configuration.
        //
        // You can access the incoming request details using the following helper functions:
        //
        // - "@(request.path())"
        // - "@(request.method())"
        // - "@(request.headers("HEADER"))"
        // - "@(request.data())"
        // - "@(request.params("PARAMS"))"
        //
        // And use the following functions for file upload related functions
        //
        // - "@(request.file("FILENAME"))"
        // - "@(request.filetype("FILENAME"))"
        // - "@(request.filepath("FILENAME"))"
        // - "@(request.filecount())"
        // - "@(request.files())"
        // - "@(request.filetypes())"
        // - "@(request.filesByType("image/jpeg"))"
        //
        // For example, to use these in your resource, you can define a local variable like this:
        //
        // local xApiHeader = "@(request.headers["X-API-HEADER"])"
        // You can then retrieve the value with "@(xApiHeader)".
        //
        // The "@(...)" syntax enables lazy evaluation, ensuring that values are
        // retrieved only after the result is ready.
        APIServer {
                // Set the host IP address and port number for the AI Agent.
                HostIP = "127.0.0.1"
                PortNum = 3000

                // You can define multiple routes for this agent. Each route points to
                // the main targetActionID specified in the targetActionID setting, so you must define
                // your skip condition on the resources appropriately.
                Routes {
                        new {
                                Path = "/api/v1/imagegen"
                                Methods {
                                        "GET" // Allows submitting data
                                }
                        }
                }
        }

        // This section contains the agent settings that will be used to build
        // the agent's Docker image.
        AgentSettings {
                // Specify if Anaconda will be installed (Warning: Docker image size will grow to ~20Gb)
                InstallAnaconda = false

                // Conda packages to be installed if installAnaconda is true
                CondaPackages {
                        // The environment is defined here.
                        // ["base"] {
                        // Mapped to the conda channel and package name
                        //     ["main"] = "pip diffusers numpy"
                        //     ["pytorch"] = "pytorch"
                        //     ["conda-forge"] = "tensorflow pandas keras transformers"
                        // }
                }

                // List of preinstalled Python packages.
                PythonPackages {
                        "diffusers"
                        "torch"
                        "huggingface_hub[cli]"
                        "transformers"
                        "accelerate"
                        "protobuf"
                        "sentencepiece"
                        "bitsandbytes"
                }

                // Specify the custom Ubuntu repo or PPA repos that would contain the packages available
                // for this image.
                Repositories {
                        // "ppa:alex-p/tesseract-ocr-devel"
                }

                // Specify the Ubuntu packages that should be pre-installed when
                // building this image.
                Packages {
                        // "tesseract-ocr"
                        // "poppler-utils"
                }

                // List the local Ollama LLM models that will be pre-installed.
                // You can specify multiple models here.
                Models {
                        // "tinydolphin"
                        //"llama3.1"
                        // "llama3.2-vision"
                        // "llama3.2"
                }

                // When set to true, models are pulled during Docker build time and stored offline.
                // At runtime, models are copied from the image to the shared volume instead of being downloaded.
                // This enables true offline operation without internet connectivity.
                OfflineMode = false

                // The Ollama image tag version to be used as a base Docker image for this AI agent.
                OllamaImageTag = "0.9.6"

                // A mapping of build argument variable names.
                Args {
                        ["HF_TOKEN"] = "secret"
                }

                // A mapping of environment variable names for the build that persist in both the image and the container.
                Env {
                        ["HF_HOME"] = "/.kdeps//huggingface"
                }
        }
}
